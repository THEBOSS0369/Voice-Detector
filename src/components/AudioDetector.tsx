"use client";
import { useState, useEffect } from "react";
import {
  Upload,
  AlertCircle,
  InfoIcon,
  Cpu,
  UserIcon,
  PlayCircle,
} from "lucide-react";
import { Alert, AlertDescription, AlertTitle } from "@/components/ui/alert";

// Define detailed result type
interface DetectionResult {
  isAI: boolean;
  confidence: number;
  message: string;
  details: {
    modelPrediction: string;
    audioFeatures: {
      pitch: number;
      rhythm: number;
      naturalness: number;
      artifacts: number;
    };
    anomalies: string[];
  };
}

const AudioDetector = () => {
  const [file, setFile] = useState<File | null>(null);
  const [isLoading, setIsLoading] = useState(false);
  const [result, setResult] = useState<DetectionResult | null>(null);
  const [audioUrl, setAudioUrl] = useState<string | null>(null);
  const [analyzedCount, setAnalyzedCount] = useState(0);

  const handleFileChange = (event: React.ChangeEvent<HTMLInputElement>) => {
    const selectedFile = event.target.files?.[0];
    if (selectedFile && selectedFile.type.startsWith("audio/")) {
      setFile(selectedFile);
      setResult(null);

      // Create URL for audio preview
      if (audioUrl) URL.revokeObjectURL(audioUrl);
      setAudioUrl(URL.createObjectURL(selectedFile));
    }
  };

  // Demo analysis function that checks filename for keywords
  const simulateAudioAnalysis = (filename: string): DetectionResult => {
    // Convert filename to lowercase for easier matching
    const lowerFilename = filename.toLowerCase();

    // Check if filename contains "ai", "agent", "bot", "generated", "synthetic"
    const aiKeywords = [
      "ai",
      "agent",
      "bot",
      "generated",
      "synthetic",
      "clone",
      "fake",
    ];
    const isAIByName = aiKeywords.some((keyword) =>
      lowerFilename.includes(keyword),
    );

    // Random variation for demo purposes
    const randomVariance = Math.random() * 15;

    if (isAIByName) {
      // AI-generated audio result
      return {
        isAI: true,
        confidence: 85 + randomVariance / 3,
        message: "This audio shows characteristics of AI-generated speech.",
        details: {
          modelPrediction: "Likely generated by a neural TTS model",
          audioFeatures: {
            pitch: 35 + randomVariance,
            rhythm: 40 + randomVariance,
            naturalness: 30 + randomVariance,
            artifacts: 75 - randomVariance,
          },
          anomalies: [
            "Unnatural pauses detected",
            "Robotic voice inflection",
            "Missing breath sounds",
            "Uniform speech patterns",
          ],
        },
      };
    } else {
      // Human audio result
      return {
        isAI: false,
        confidence: 90 + randomVariance / 3,
        message: "This audio appears to be from a natural human source.",
        details: {
          modelPrediction: "Natural human speech",
          audioFeatures: {
            pitch: 85 - randomVariance,
            rhythm: 88 - randomVariance,
            naturalness: 92 - randomVariance,
            artifacts: 15 + randomVariance,
          },
          anomalies: [],
        },
      };
    }
  };

  const handleUpload = async () => {
    if (!file) return;
    setIsLoading(true);

    // Simulate network delay for realism
    setTimeout(() => {
      try {
        // For demo, we'll use the filename to determine if it's AI or not
        const result = simulateAudioAnalysis(file.name);
        setResult(result);
        setAnalyzedCount((prev) => prev + 1);
      } catch (error) {
        setResult({
          isAI: false,
          confidence: 0,
          message: "Error processing audio. Please try again.",
          details: {
            modelPrediction: "Analysis failed",
            audioFeatures: {
              pitch: 0,
              rhythm: 0,
              naturalness: 0,
              artifacts: 0,
            },
            anomalies: ["Processing error"],
          },
        });
      } finally {
        setIsLoading(false);
      }
    }, 2500); // 2.5 second delay to simulate processing
  };

  // Function to render feature bars
  const renderFeatureBar = (
    value: number,
    label: string,
    lowIsGood: boolean = false,
  ) => {
    // Determine color based on value and whether low or high is good
    const getColor = () => {
      if (lowIsGood) {
        // For metrics where low values are good (like artifacts)
        return value < 30
          ? "bg-gradient-to-r from-emerald-500 to-green-400"
          : value < 70
            ? "bg-gradient-to-r from-yellow-500 to-orange-400"
            : "bg-gradient-to-r from-red-500 to-pink-400";
      } else {
        // For metrics where high values are good
        return value > 70
          ? "bg-gradient-to-r from-emerald-500 to-green-400"
          : value > 30
            ? "bg-gradient-to-r from-yellow-500 to-orange-400"
            : "bg-gradient-to-r from-red-500 to-pink-400";
      }
    };

    return (
      <div className="mb-2">
        <div className="flex justify-between mb-1">
          <span className="text-sm text-gray-300">{label}</span>
          <span className="text-sm text-gray-300">{value.toFixed(1)}%</span>
        </div>
        <div className="w-full bg-neutral-700 rounded-full h-2.5">
          <div
            className={`h-2.5 rounded-full ${getColor()}`}
            style={{ width: `${value}%` }}
          ></div>
        </div>
      </div>
    );
  };

  return (
    <div className="bg-neutral-950 min-h-screen">
      <div className="relative h-20 ">
        <div className="absolute bottom-0 left-0 right-0 h-[1px] bg-gradient-to-r from-transparent via-gray-500 to-transparent"></div>
      </div>

      <div className="mt-20">
        <h1 className="text-6xl text-white font-bold text-center p-2 tracking-tight">
          Audio Detective:
        </h1>
        <h1 className="text-6xl text-white font-bold text-center p-3 tracking-tight">
          <span className="bg-clip-text text-transparent bg-gradient-to-r from-blue-400 to-emerald-400">
            AI Audio Analysis
          </span>
          Hub.
        </h1>

        <div className="flex text-white items-center justify-center">
          <p className="p-10 text-center text-lg">
            Upload your audio file and instantly detect if it's AI-generated,
            <br />
            from{" "}
            <span className="font-bold bg-clip-text text-transparent bg-gradient-to-r from-emerald-400 to-blue-400">
              voice recordings to synthetic speech.
            </span>
            <br />
            Your audio, our analysis!
          </p>
        </div>
      </div>

      <div className="flex items-center justify-center px-6 mb-12">
        <div className="bg-neutral-800 rounded-lg p-8 w-full max-w-2xl">
          <div className="border-2 border-dashed border-neutral-600 rounded-lg p-8 text-center">
            <input
              type="file"
              accept="audio/*"
              onChange={handleFileChange}
              className="hidden"
              id="audio-input"
            />
            <label
              htmlFor="audio-input"
              className="cursor-pointer flex flex-col items-center"
            >
              <Upload className="w-12 h-12 text-gray-400 mb-4" />
              <span className="text-gray-400">
                {file ? file.name : "Click to upload audio file"}
              </span>
              <span className="text-xs text-gray-500 mt-2">
                {!file &&
                  "For demo: files with 'agent', 'ai', 'bot' in the name will be detected as AI"}
              </span>
            </label>
          </div>

          {audioUrl && (
            <div className="mt-4">
              <div className="flex items-center text-gray-300 text-sm mb-1">
                <PlayCircle className="h-4 w-4 mr-1" />
                <span>Audio Preview</span>
              </div>
              <audio controls className="w-full mt-1" src={audioUrl}></audio>
            </div>
          )}

          {file && (
            <button
              onClick={handleUpload}
              disabled={isLoading}
              className="w-full mt-6 bg-gradient-to-r from-blue-500 to-emerald-500 text-white py-2 px-4 rounded-lg hover:opacity-90 disabled:opacity-50 transition"
            >
              {isLoading ? "Analyzing..." : "Analyze Audio"}
            </button>
          )}

          {result && (
            <div className="mt-6 space-y-4">
              <Alert
                variant={result.isAI ? "destructive" : "default"}
                className={`bg-neutral-700 border-${result.isAI ? "red" : "green"}-500`}
              >
                {result.isAI ? (
                  <Cpu className="h-4 w-4 text-red-400" />
                ) : (
                  <UserIcon className="h-4 w-4 text-green-400" />
                )}
                <AlertTitle className="text-white">
                  {result.isAI
                    ? "AI Generated Audio Detected"
                    : "Natural Human Audio Detected"}
                </AlertTitle>
                <AlertDescription className="text-gray-300">
                  <div className="font-bold">
                    Confidence: {result.confidence.toFixed(1)}%
                  </div>
                  <div className="mt-1">{result.message}</div>
                </AlertDescription>
              </Alert>

              {/* Detailed Analysis Section */}
              <div className="bg-neutral-700 rounded-lg p-4">
                <h3 className="text-white font-semibold flex items-center mb-4">
                  <InfoIcon className="h-4 w-4 mr-2" />
                  Detailed Analysis
                </h3>

                {/* Audio Features */}
                <div className="mb-4">
                  <h4 className="text-white text-sm font-medium mb-2">
                    Audio Characteristics
                  </h4>
                  {renderFeatureBar(
                    result.details.audioFeatures.naturalness,
                    "Natural Speech",
                  )}
                  {renderFeatureBar(
                    result.details.audioFeatures.rhythm,
                    "Natural Rhythm",
                  )}
                  {renderFeatureBar(
                    result.details.audioFeatures.pitch,
                    "Pitch Variation",
                  )}
                  {renderFeatureBar(
                    result.details.audioFeatures.artifacts,
                    "Artifacts Present",
                    true,
                  )}
                </div>

                {/* AI Model Prediction */}
                <div className="text-white text-sm mb-3">
                  <span className="font-medium">Classification:</span>{" "}
                  {result.details.modelPrediction}
                </div>

                {/* Anomalies */}
                {result.details.anomalies &&
                  result.details.anomalies.length > 0 && (
                    <div>
                      <h4 className="text-white text-sm font-medium mb-2">
                        Detected Anomalies
                      </h4>
                      <ul className="text-gray-300 text-sm space-y-1 list-disc pl-5">
                        {result.details.anomalies.map((anomaly, index) => (
                          <li key={index}>{anomaly}</li>
                        ))}
                      </ul>
                    </div>
                  )}

                {/* Demo Stats */}
                <div className="mt-4 pt-4 border-t border-neutral-600 text-xs text-gray-400">
                  Analysis #{analyzedCount} | Demo Mode
                </div>
              </div>
            </div>
          )}
        </div>
      </div>
    </div>
  );
};

export default AudioDetector;
